# Context Stack Validation Metrics

## ðŸŽ¯ **MÃ©tricas de VerificaciÃ³n del Context Stack**

Este documento define mÃ©tricas cuantificables para validar que el Context Stack profesional estÃ¡ realmente aportando valor al proyecto DungeonDra.

---

## ðŸ“Š **MÃ©tricas de Calidad de CÃ³digo**

### 1. **Adherencia ArquitectÃ³nica**
**Objetivo**: Verificar que el cÃ³digo sigue Clean Architecture

```bash
# Comandos de verificaciÃ³n
npm run typecheck    # 0 errores TypeScript
npm run lint         # 0 warnings ESLint
```

**MÃ©tricas**:
- âœ… **0 errores TypeScript** en build de producciÃ³n
- âœ… **0 warnings ESLint** en anÃ¡lisis estÃ¡tico
- âœ… **100% interfaces TypeScript** para contratos entre capas
- âœ… **0 imports directos** de frontend a backend (verificar con lint rules)

### 2. **Calidad de DocumentaciÃ³n**
**Objetivo**: Context Stack completo y actualizado

**MÃ©tricas**:
- âœ… **CLAUDE.md actualizado** con Product Goal, Key Features, User Flow, Tech Stack, Design Principles
- âœ… **3+ documentos en .claude/rules/** (project-overview, api-routes, game-mechanics)
- âœ… **design/system.json** con tokens extraÃ­dos y organizados
- âœ… **Component conventions** documentadas y seguidas

### 3. **Consistencia de DiseÃ±o**
**Objetivo**: Uso sistemÃ¡tico de design tokens

**MÃ©tricas verificables**:
```bash
# Buscar hardcoded colors en componentes
grep -r "#[0-9a-fA-F]\{6\}" frontend/src/components/ --exclude-dir=node_modules

# Verificar uso de design tokens
grep -r "var(--" frontend/src/ --include="*.css" | wc -l

# Contar componentes que siguen convenciones de naming
find frontend/src/components -name "*.tsx" | wc -l
```

**Targets**:
- âœ… **<5 colores hardcodeados** en componentes nuevos
- âœ… **80%+ uso de design tokens** en CSS
- âœ… **100% componentes** siguen naming convention

---

## ðŸš€ **MÃ©tricas de Performance**

### 1. **Tiempos de Desarrollo**
**Objetivo**: Context Stack reduce tiempo de toma de decisiones

**MÃ©tricas**:
- â±ï¸ **<30 segundos** para Claude encontrar informaciÃ³n arquitectÃ³nica
- â±ï¸ **<60 segundos** para generar componente siguiendo convenciones
- â±ï¸ **<120 segundos** para implementar nueva feature respetando Clean Architecture

### 2. **Build Performance**
**Objetivo**: Mantener performance de desarrollo

```bash
# Tiempo de build
time npm run build

# TamaÃ±o de bundle
du -sh public/assets/*.js

# Tiempo de hot reload
# (medir manualmente en desarrollo)
```

**Targets**:
- âœ… **<30 segundos** build completo
- âœ… **<500KB** bundle JS total
- âœ… **<2 segundos** hot reload en desarrollo

---

## ðŸŽ® **MÃ©tricas de Experiencia de Usuario**

### 1. **Cumplimiento de Product Goals**
**Objetivo**: Features implementadas cumplen objetivos definidos

**MÃ©tricas verificables**:
```bash
# Verificar que la aplicaciÃ³n arranca
npm run health

# Tiempo de startup
time npm start
```

**Targets desde CLAUDE.md**:
- âœ… **<5 minutos** setup completo (crear personaje + iniciar aventura)
- âœ… **<3 segundos** respuesta IA promedio
- âœ… **60fps** animaciones de dados
- âœ… **<2 segundos** startup aplicaciÃ³n

### 2. **LocalizaciÃ³n EspaÃ±ola**
**Objetivo**: 100% interfaz en espaÃ±ol

```bash
# Buscar texto en inglÃ©s hardcodeado
grep -r "\"[A-Z][a-z].*[a-z]\"" frontend/src/ --include="*.tsx" --include="*.ts"

# Verificar mensajes de error en espaÃ±ol
grep -r "Error\|error" src/ --include="*.ts" | grep -v "console"
```

**Targets**:
- âœ… **0 strings en inglÃ©s** en interfaz usuario
- âœ… **100% mensajes error** en espaÃ±ol
- âœ… **Nombres NPCs/lugares** espaÃ±olizados en IA

---

## ðŸ” **MÃ©tricas de Mantenibilidad**

### 1. **Complejidad de CÃ³digo**
**Objetivo**: CÃ³digo fÃ¡cil de entender y modificar

```bash
# Contar lÃ­neas por archivo (detectar archivos muy grandes)
find src/ -name "*.ts" -o -name "*.tsx" | xargs wc -l | sort -n

# Verificar que entities tienen validaciÃ³n
grep -r "validate" src/domain/entities/

# Contar casos de uso con manejo de errores
grep -r "try\|catch\|throw" src/application/use-cases/
```

**Targets**:
- âœ… **<200 lÃ­neas** promedio por archivo TypeScript
- âœ… **100% entities** tienen validaciÃ³n en constructor
- âœ… **100% use cases** tienen manejo de errores
- âœ… **100% servicios** implementan interfaces

### 2. **Dependencias y Acoplamiento**
**Objetivo**: Bajo acoplamiento entre capas

```bash
# Verificar imports entre capas (no deberÃ­a haber)
grep -r "import.*presentation" src/domain/
grep -r "import.*infrastructure" src/domain/
grep -r "import.*src/" frontend/src/

# Contar interfaces vs implementaciones
find src/ -name "I*.ts" | wc -l  # Interfaces
find src/ -name "*Service.ts" | wc -l  # Servicios
```

**Targets**:
- âœ… **0 imports** de capas superiores en domain/
- âœ… **Ratio 1:1** interfaces/implementaciones para servicios
- âœ… **0 imports directos** frontend â†’ backend

---

## ðŸ¤– **MÃ©tricas de IA Integration**

### 1. **Calidad de GeneraciÃ³n de Historias**
**Objetivo**: IA produce contenido coherente y usable

**MÃ©tricas verificables**:
```bash
# Verificar manejo de errores IA
grep -r "retry\|fallback" src/infrastructure/services/GeminiAIService.ts

# Comprobar que responses se parsean correctamente
grep -r "parseResponse" src/infrastructure/services/
```

**Targets**:
- âœ… **3+ reintentos** automÃ¡ticos para fallos IA
- âœ… **100% responses** tienen fallback content
- âœ… **95%+ parsing success** de respuestas IA
- âœ… **100% historias** en espaÃ±ol sin NPCs en inglÃ©s

### 2. **IntegraciÃ³n Dados + IA**
**Objetivo**: Sistema de dados integrado con narrativa

```bash
# Verificar que todas las opciones tienen dados asociados
grep -r "diceRequest" src/infrastructure/services/GeminiAIService.ts

# Comprobar tipos de dados vÃ¡lidos
grep -r "diceType.*4\|6\|8\|10\|12\|20\|100" frontend/src/components/
```

**Targets**:
- âœ… **100% opciones historia** tienen dice requests asociados
- âœ… **100% dice requests** tienen DC vÃ¡lido (5-30)
- âœ… **7 tipos dados** soportados completamente

---

## ðŸŽ¯ **KPIs de Context Stack Effectiveness**

### MÃ©tricas de Impacto:

**Before vs After Context Stack:**

| MÃ©trica | Antes | Objetivo Post Context Stack | VerificaciÃ³n |
|---------|-------|---------------------------|--------------|
| Tiempo decisiones arquitectÃ³nicas | ~5 min | <1 min | Manual (cronÃ³metro) |
| Errores convenciÃ³n naming | ~20% | <5% | `grep -r` patterns |
| Components sin TypeScript interfaces | ~30% | 0% | `npm run typecheck` |
| Hardcoded colors/styles | ~50 instances | <10 instances | `grep -r "#[0-9a-fA-F]"` |
| API endpoints sin documentar | 100% | 0% | Check .claude/rules/api-routes.md |
| Tiempo implementar nueva feature | ~60 min | <30 min | Manual (cronÃ³metro) |

---

## ðŸ”„ **Script de ValidaciÃ³n AutomÃ¡tica**

```bash
#!/bin/bash
# .claude/validation/validate-context-stack.sh

echo "ðŸ” VALIDANDO CONTEXT STACK DUNGEONRA..."

# 1. Verificar calidad cÃ³digo
echo "ðŸ“Š Verificando TypeScript..."
npm run typecheck || echo "âŒ Errores TypeScript encontrados"

echo "ðŸ“Š Verificando ESLint..."
npm run lint || echo "âŒ Warnings ESLint encontrados"

# 2. Verificar documentaciÃ³n
echo "ðŸ“– Verificando documentaciÃ³n..."
[ -f "CLAUDE.md" ] && echo "âœ… CLAUDE.md presente" || echo "âŒ CLAUDE.md faltante"
[ -d ".claude/rules" ] && echo "âœ… .claude/rules presente" || echo "âŒ .claude/rules faltante"
[ -f "design/system.json" ] && echo "âœ… design/system.json presente" || echo "âŒ design tokens faltantes"

# 3. Verificar convenciones
echo "ðŸŽ¨ Verificando design consistency..."
hardcoded_colors=$(grep -r "#[0-9a-fA-F]\{6\}" frontend/src/components/ --exclude-dir=node_modules | wc -l)
echo "ðŸŽ¯ Colores hardcoded encontrados: $hardcoded_colors (objetivo: <5)"

# 4. Verificar localizaciÃ³n
echo "ðŸŒ Verificando localizaciÃ³n espaÃ±ola..."
english_strings=$(grep -r "\"[A-Z][a-z].*[a-z]\"" frontend/src/ --include="*.tsx" --include="*.ts" | wc -l)
echo "ðŸŽ¯ Strings en inglÃ©s encontrados: $english_strings (objetivo: 0)"

# 5. Performance
echo "âš¡ Verificando performance..."
echo "ðŸ—ï¸ Ejecutando build..."
time npm run build

echo "ðŸ“¦ Verificando tamaÃ±o bundle..."
du -sh public/assets/*.js 2>/dev/null || echo "âŒ No se encontraron archivos de build"

# Resultado final
echo ""
echo "âœ… VALIDACIÃ“N COMPLETADA"
echo "ðŸ“‹ Revisar mÃ©tricas arriba para cumplimiento de objetivos"
```

---

## ðŸ“ˆ **Dashboard de MÃ©tricas**

**Crear archivo**: `.claude/validation/metrics-dashboard.md`

```markdown
# Metrics Dashboard - Ãšltima ActualizaciÃ³n: YYYY-MM-DD

## ðŸŽ¯ Estado Actual Context Stack

### Code Quality
- TypeScript Errors: âŒ/âœ… (target: 0)
- ESLint Warnings: âŒ/âœ… (target: 0)  
- Test Coverage: XX% (target: >80%)

### Documentation
- CLAUDE.md Sections: 5/5 âœ…
- .claude/rules Files: 3/3 âœ…
- Design Tokens: âœ…

### Performance
- Build Time: XXs (target: <30s)
- Bundle Size: XXXkb (target: <500kb)
- Hot Reload: XXs (target: <2s)

### User Experience  
- Spanish Localization: XX% (target: 100%)
- Error Handling: XX% (target: 100%)
- Accessibility: XX% (target: 90%+)

## ðŸ“Š Trending
- [Previous week metrics for comparison]
```

---

**Uso de estas mÃ©tricas**:
1. **Ejecutar validaciÃ³n** antes de cada commit importante
2. **Actualizar dashboard** semanalmente  
3. **Revisar KPIs** cuando Context Stack no parezca estar ayudando
4. **Iterar en documentation** basado en mÃ©tricas de efectividad

**Objetivo**: Demostrar con datos que el Context Stack profesional estÃ¡ mejorando velocidad de desarrollo, calidad de cÃ³digo y consistencia del proyecto.